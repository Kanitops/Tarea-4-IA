# Tarea 4: Reinforcement Learning - Q-Learning

**Curso:** TICS315 - Inteligencia Artificial  
**ImplementaciÃ³n:** Q-Learning aplicado a un entorno de juego 2D con grid

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un agente de **Reinforcement Learning** utilizando el algoritmo **Q-Learning** para navegar en un entorno de juego donde un hÃ©roe ğŸ™ƒ debe:

- âœ… Recolectar trofeos ğŸ†
- âŒ Evitar zombies ğŸ§Ÿ (o vencerlos con espada ğŸ—¡ï¸)
- ğŸ”‘ Conseguir llaves para abrir puertas ğŸšª
- ğŸš« Navegar evitando obstÃ¡culos

## ğŸ® Elementos del Juego

| Emoji | Elemento | DescripciÃ³n |
|-------|----------|-------------|
| ğŸ™ƒ | HÃ©roe | Agente controlado por Q-Learning |
| ğŸ† | Trofeo | Objetivo principal (+100 pts) |
| ğŸ§Ÿ | Zombie | Enemigo (-100 sin espada, +50 con espada) |
| ğŸ”‘ | Llave | Permite abrir puertas (+75 pts) |
| ğŸšª | Puerta | Requiere llave para pasar |
| ğŸ—¡ï¸ | Espada | Permite vencer zombies (+75 pts) |
| ğŸš« | Bloque | ObstÃ¡culo infranqueable |
| âšª | VacÃ­o | Espacio libre (-1 pt por movimiento) |

## ğŸš€ InstalaciÃ³n y EjecuciÃ³n

### Prerrequisitos

- Python 3.12+ (compatible con 3.8+)
- pip (gestor de paquetes)

### Pasos de InstalaciÃ³n

```bash
# 1. Clonar el repositorio
git clone https://github.com/Kanitops/Tarea-4-IA.git
cd Tarea-4-IA

# 2. Crear entorno virtual (opcional pero recomendado)
python3 -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Ejecutar Jupyter Lab
jupyter lab
```

### EjecuciÃ³n del Notebook

1. Abrir `Tarea 4 - RL - Q-Learning - Solucion.ipynb`
2. Ejecutar todas las celdas en orden (Cell â†’ Run All)
3. Observar el entrenamiento y resultados

## ğŸ“Š Resultados del Entrenamiento

El agente logra una mejora significativa durante el entrenamiento:

- **Episodios de entrenamiento:** 400
- **Recompensa promedio inicial:** ~193 puntos
- **Recompensa promedio final:** ~2312 puntos
- **Mejora total:** +1097.8% ğŸ¯
- **Estados explorados:** 429 Ãºnicos

### VisualizaciÃ³n del Aprendizaje

![GrÃ¡fica de aprendizaje](docs/learning_curve.png)

La grÃ¡fica muestra:
- **Izquierda:** ProgresiÃ³n episodio a episodio con media mÃ³vil
- **Derecha:** ComparaciÃ³n boxplot primeros vs Ãºltimos 50 episodios

## ğŸ§  Algoritmo Q-Learning

### FÃ³rmula Implementada

```
Q_nuevo(s, a) = Q(s, a) + Î± * [r + Î³ * max(Q(s', a')) - Q(s, a)]
```

Donde:
- `s`: Estado actual
- `a`: AcciÃ³n tomada
- `r`: Recompensa recibida
- `s'`: Nuevo estado
- `Î±`: Tasa de aprendizaje (learning rate)
- `Î³`: Factor de descuento (discount factor)

### HiperparÃ¡metros Utilizados

```python
N_EPISODES = 400           # Total de episodios de entrenamiento
MAX_EPISODE_STEPS = 200    # Pasos mÃ¡ximos por episodio
gamma = 0.95               # Factor de descuento (valora futuro)
alpha = 1.0 â†’ 0.05         # Tasa de aprendizaje decreciente
epsilon = 0.4 â†’ 0.05       # ExploraciÃ³n Îµ-greedy decreciente
```

## ğŸ“ Preguntas Resueltas

El notebook incluye respuestas detalladas a 7 preguntas pedagÃ³gicas:

1. âœ… ImplementaciÃ³n de bloques, puertas y llaves
2. âœ… Sistema de espada para vencer zombies
3. âœ… Ajuste de hiperparÃ¡metros para mapas complejos
4. âœ… JustificaciÃ³n tÃ©cnica de los cambios
5. âœ… AnÃ¡lisis de recompensas negativas por movimiento

## ğŸ“ Estructura del Proyecto

```
Tarea-4-IA/
â”œâ”€â”€ README.md                                    # Este archivo
â”œâ”€â”€ AGENTS.md                                    # GuÃ­a para desarrolladores
â”œâ”€â”€ requirements.txt                             # Dependencias Python
â”œâ”€â”€ Tarea 4 - RL - Q-Learning (1).ipynb         # Notebook original (plantilla)
â”œâ”€â”€ Tarea 4 - RL - Q-Learning - Solucion.ipynb  # Notebook con soluciones
â”œâ”€â”€ tarea4-IA-2025 (1).pdf                      # Instrucciones de la tarea
â”œâ”€â”€ rubrica-tarea-IA-RL (1).xlsx                # RÃºbrica de evaluaciÃ³n
â””â”€â”€ .gitignore                                   # Archivos ignorados por Git
```

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.13.7**
- **NumPy** - Operaciones numÃ©ricas y matrices
- **Jupyter Lab** - Entorno interactivo
- **Matplotlib** - VisualizaciÃ³n de resultados

## ğŸ‘¥ Autores

- Integrante 1
- Integrante 2
- Integrante 3
- Integrante 4

## ğŸ“š Referencias

- Sutton, R. S., & Barto, A. G. (2018). *Reinforcement Learning: An Introduction*
- Material del curso TICS315 - Inteligencia Artificial
- [OpenAI Gym Documentation](https://gymnasium.farama.org/)

## ğŸ“„ Licencia

Este proyecto es material acadÃ©mico para el curso TICS315.

---

**Fecha de Ãºltima actualizaciÃ³n:** 28 de noviembre de 2025
